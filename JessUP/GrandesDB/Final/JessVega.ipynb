{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Muestreo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para analizar la calidad del conjunto de datos, seleccionar variables, limpiar y transformar los datos y finalmente determinar un número $k$ de clusters partiremos de un muestreo del conjunto de datos inicial, con un tamaño de muestra del 20% con respecto al original (porque la memoria RAM nos lo permite). \n",
    "\n",
    "Para el muestreo utilizamos el método de __reservoir sapling__ visto en clase.\n",
    "\n",
    "Como el conjunto de datos cuenta con más de 5 millones de registros, segun su [documentación](https://data.sfgov.org/Public-Safety/Fire-Department-Calls-for-Service/nuek-vuh3) fijamos el tamaño de muestra:\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_muestras <- 5.4*(1*10**6)/5\n",
    "t1 <- Sys.time()\n",
    "dir()\n",
    "print(n_muestras)\n",
    "set.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path.file <- \"Fire_Department_Calls_for_Service.csv\" #--path donde se encuentra el conjunto de datos original \n",
    "n_filas_read <- 500000 # la rm nos permite cargar este numero de registros y agilizar el muestreo\n",
    "\n",
    "connection <- file(path.file, open = \"r\")\n",
    "#--nombre de las columnas (primera fila)\n",
    "#col_names  <- read.csv(connection, nrows = 1, header = TRUE)\n",
    "#--definimos nuestro buffer (muestra) y los rellenamos con las primeras n_muestras filas\n",
    "buffer <- read.csv(connection, nrows = n_muestras, header = TRUE, stringsAsFactors = FALSE)\n",
    "\n",
    "#--indice que nos permitira generar los numeros aleatorios correctamente\n",
    "posicion_inicial <- n_muestras\n",
    "random_unif <- function(x) sample.int(x,1)\n",
    "\n",
    "contador <- 1\n",
    "repeat{\n",
    "  print(paste0(\"Posicion inicial: \", posicion_inicial))\n",
    "  \n",
    "   #--leemos una parte del archivo\n",
    "  temp <- read.csv(connection, nrows = n_filas_read, header = FALSE)\n",
    "\n",
    "  #--indices que controlan el maximo de cada numero aleatorio\n",
    "  maximo <- c(1:nrow(temp)) + posicion_inicial\n",
    "\n",
    "  #--generamos numeros aleatorios de forma vectorizada, segun esto solo permuta los indices\n",
    "  j = vapply(maximo, random_unif, FUN.VALUE = integer(1))\n",
    "\n",
    "  #--observamos cuales de los numeros aleatorios son menores que nuestra muestra\n",
    "  idx <- j <= n_muestras\n",
    "\n",
    "  #--sustituimos los que resultaron menores\n",
    "  buffer[j[idx], ] <- temp[idx, ]\n",
    "  \n",
    "  print(paste0(\"iteracion: \", contador))\n",
    "  contador <- contador + 1\n",
    "  #--redefinimos la posicion inicial para la siguiente iteracion\n",
    "  posicion_inicial <- posicion_inicial + nrow(temp)\n",
    "  \n",
    "  #--si el numero de filas leidas es menor que el esperado,\n",
    "  #-asumimos que se acabo el archivo y salimos del ciclo\n",
    "  if(nrow(temp) < n_filas_read)\n",
    "    break\n",
    "}\n",
    "t2 <- Sys.time()\n",
    "print(t2 - t1) #(Time difference of 9.29019 mins mins )\n",
    "#--guardar nuestra muestra para un futuro analisis\n",
    "write.csv(buffer, paste0(\"muestra_\", path.file), row.names = FALSE )\n",
    "close(connection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "library(readr)\n",
    "data <- read_csv('muestra3_Fire_Department_Calls_for_Service.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dim(data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Después de leer la documentación y entender la estructura de la data, decidimos que el cluster que realizaremos tendrá como objetivo encontrar grupos de llamadas parecidas entre sí y contrastaremos estos grupos con la etiqueta que poseen los datos en la columna `Call Type Group`.\n",
    "Después de revisar la documentación  descartamos las columnas `Call.Type`, `RowID`, `Unit ID`, `Incident Number`, `Unit Type`, `Unit sequence in call dispatch` al igual que `Location`. Las primeras por no aportar información extra y la última porque la documentación no proporciona el tipo de proyección utilizado para referencias las coordenadas de los puntos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data$RowID <- data$Unit.ID <- data$Incident.Number <- data$Location <- data$Unit.Type <- data$Unit.sequence.in.call.dispatch <- data$Call.Type <- NULL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En vista de que las siguientes columnas no se encuentran [documentadas en el diccionario de datos correspondiente](https://data.sfgov.org/api/views/nuek-vuh3/files/ddb7f3a9-0160-4f07-bb1e-2af744909294?download=true&filename=FIR-0002_DataDictionary_fire-calls-for-service.xlsx) procedemos a eliminarlas:\n",
    "`Current Police Districts`, `Neighborhoods - Analysis Boundaries` , `Zip Codes`, `Neighborhoods (old)`, `Police Districts`, `Civic Center Harm Reduction Project Boundary`, `HSOC Zones` y  `Central Market/Tenderloin Boundary Polygon - Updated`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[ , c('Current.Police.Districts', 'Neighborhoods...Analysis.Boundaries', 'Zip.Codes', 'Neighborhoods..old.', 'Police.Districts', \n",
    "          'Civic.Center.Harm.Reduction.Project.Boundary', 'HSOC.Zones', 'Central.Market.Tenderloin.Boundary.Polygon...Updated')] <- NULL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "head(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Procedemos a retener el último registro de cada llamada, el cual contiene la información acumulada de los anteriores. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "library(dplyr)\n",
    "library(lubridate)\n",
    "data$Received.DtTm <- mdy_hms(data$Received.DtTm)\n",
    "data %>% group_by(Call.Number ) %>% arrange(Call.Number , Received.DtTm ) %>% mutate( flag1 = n() ,flag2 = row_number()) -> data\n",
    "data %>% filter(flag1 ==flag2 ) -> data\n",
    "data$flag1 <- data$flag2 <- NULL\n",
    "data$Available.DtTm <- NULL\n",
    "data$Call.Date <- mdy(data$Call.Date)\n",
    "data$Watch.Date <- mdy(data$Watch.Date)\n",
    "data$Entry.DtTm <- mdy_hms(data$Entry.DtTm)\n",
    "data$Dispatch.DtTm <- mdy_hms(data$Dispatch.DtTm)\n",
    "data$Response.DtTm <- mdy_hms( data$Response.DtTm) \n",
    "data$On.Scene.DtTm <- mdy_hms( data$On.Scene.DtTm) \n",
    "data$Transport.DtTm <- mdy_hms(data$Transport.DtTm) \n",
    "data$Hospital.DtTm <- mdy_hms(data$Hospital.DtTm) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como suponemos que la duración de la llamada está correlacionada con su clasificación con las variables de tipo fecha (`Call.Date`, `Watch.Date`, `Received.DtTm`, `Entry.DtTm`, `Dispatch.DtTm`, `Response.DtTm`, `On.Scene.DtTm`, `Transport.DtTm`, `Hospital.DtTm`) obtenemos la duración aproximada de la llamada. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "head(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#install.packages('reshape2')\n",
    "library(reshape2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.t <- melt(data, id = c('Call.Number','Call.Final.Disposition', 'Address', 'City', 'Zipcode.of.Incident', 'Battalion', \n",
    "                            'Station.Area', 'Box', 'Original.Priority', 'Priority', 'Final.Priority', 'ALS.Unit', 'Call.Type.Group', \n",
    "                            'Number.of.Alarms',  'Fire.Prevention.District', 'Supervisor.District', \n",
    "                            'Neighborhooods...Analysis.Boundaries', 'Supervisor.Districts', 'Fire.Prevention.Districts' ) ) %>%\n",
    "          filter( variable %in% c('Received.DtTm', 'Entry.DtTm', 'Dispatch.DtTm', 'Response.DtTm', 'On.Scene.DtTm', 'Transport.DtTm', 'Hospital.DtTm' )) \n",
    "head(data.t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.t %>% group_by (Call.Number, Call.Final.Disposition, Address, City, Zipcode.of.Incident, Battalion, \n",
    "                            Station.Area, Box, Original.Priority, Priority, Final.Priority, ALS.Unit, Call.Type.Group, \n",
    "                            Number.of.Alarms,  Fire.Prevention.District, Supervisor.District, \n",
    "                            Neighborhooods...Analysis.Boundaries, Supervisor.Districts, Fire.Prevention.Districts  ) %>% \n",
    "      summarise( min.t = min(value, na.rm=TRUE), max.t =max(value, na.rm=TRUE)) -> data.t\n",
    "data.t <- data.t %>% mutate(Call.seconds = max.t - min.t)\n",
    "data.t$min.t <- data.t$max.t <- NULL "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "head(data.t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table(data.t$Call.Type.Group)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-means on-line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha <- 0.1\n",
    "kmeans.online.b.init <- function(data, k, alpha){\n",
    "  # clousure para distribuir la eleccion del elemento k\n",
    "  data <- data\n",
    "  alpha <- alpha\n",
    "  function(k){\n",
    "    # Entradas \n",
    "    # data (data.frame): Dataframe donde las observaciones son los elementos a clusterizar y las columnas son las variables\n",
    "    # k (int): Numero de cluster requerido\n",
    "    # alpha (numeric): learning rate\n",
    "    # Salida\n",
    "    # kmeans.online con los elementos:\n",
    "    # tabla.master (data.frame): Dos columnas, la primera con el id de la observacion y la segunda con el label del cluster\n",
    "    # statas.intra (vector): Vector con la media d ela varianza intraelementos\n",
    "    tabla.master <- data.frame(Obs = row.names(data), Cluster= rep(-Inf, dim(data)[1]))\n",
    "    # inicializacion alatoria entre el minimo y maximo de cada variable\n",
    "    stats.min <- sapply(data, min)\n",
    "    stats.max <- sapply(data, max)\n",
    "    set.seed(0)\n",
    "    centroides <- mapply(function(x, y) {runif(k, x, y)},  stats.min, stats.max) \n",
    "    # termina inicializacion de centroides\n",
    "    \n",
    "    # comienza kmeans proceso online\n",
    "    \n",
    "    for( i in 1:dim(data)[1])\n",
    "    {\n",
    "      #i <- 11\n",
    "      #print(i)\n",
    "      # comienza asignacion de cluster mas cercano\n",
    "      observacion.en.juego <- as.matrix(data[i, ])\n",
    "      m.temp <- as.matrix(rbind(observacion.en.juego, centroides))\n",
    "      distancias <- dist(m.temp)\n",
    "      m.distancias <- as.matrix(distancias)\n",
    "      k.i <- which.min(m.distancias[1, 2:(k+1)])\n",
    "      tabla.master$Cluster[i] <- k.i\n",
    "      # termina asignacion de cluster m�s cercano \n",
    "      # update de cluster\n",
    "      centroides[k.i, ] <- centroides[k.i, ] + alpha*observacion.en.juego\n",
    "    }\n",
    "    stats <- rep(-Inf, k)\n",
    "    for ( i in 1:k)\n",
    "    {\n",
    "      index <- which( tabla.master$Cluster == i)\n",
    "      data.subset <- docs.vector[ index, ]\n",
    "      stats.i <- dist(data.subset)\n",
    "      stats[i] <- sum(stats.i) # asumimos independencia entre las variables\n",
    "    }\n",
    "    kmeans.online <- list( tabla.master =tabla.master, statas.intra = stats)\n",
    "    return(kmeans.online)\n",
    "  }\n",
    "}\n",
    "data <- as.data.frame(data.t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y <- data.frame(y=data$Call.Type.Group)\n",
    "row.names(Y) <- row.names(data) <- data$Call.Number\n",
    "data$Call.Type.Group <- data$Call.Number <- NULL\n",
    "# hacemos un cambio de encoding "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index <- which(sapply(data, class) == 'character')\n",
    "normalizar <- function(x, na.rm = FALSE) (x - mean(x, na.rm = na.rm)) / sd(x, na.rm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for (i in index)\n",
    "    {\n",
    "    index.na <- which( is.na(data[, i] ))\n",
    "    data[index.na, i] <- 'NULL'\n",
    "    temp <- factor( data[, i])\n",
    "    data[, i] <- normalizar(as.numeric( temp))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "head(data)\n",
    "print(dim(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans.online.b <- kmeans.online.b.init(data = data, alpha = alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set.seed(0)\n",
    "cluster <- 1:3\n",
    "for( i in 1:3)\n",
    "{\n",
    "  print(i)\n",
    "  res <- kmeans.online.b(k=i+1)\n",
    "  cluster[i] <- sum(res$statas.intra)\n",
    "  print(cluster)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot((cluster),type = 'l', xlab = 'Multiplos de 5', ylab = 'Var intra cluster')\n",
    "plot(abs(diff(cluster)),type = 'l',  xlab = 'Multiplos de 5', ylab = 'diff(Var) intra cluster')\n"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "name": "r-cpu.3-6.m55",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/r-cpu.3-6:m55"
  },
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
