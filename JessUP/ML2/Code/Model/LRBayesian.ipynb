{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recolección de datos\n",
    "\n",
    "Esta parte la puede detallar mejor Jessica"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocesamiento y extracción de características\n",
    "\n",
    "Una vez que definimos las columnas, o variables, que utilizaremos en la construcción del dataset recurrimos a reglas del negocio para saber como tratar los valores *en blanco* o nulos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' libraries'''\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from plotnine import *\n",
    "''' config notebook ''' \n",
    "%matplotlib inline\n",
    "\n",
    "datos = pd.read_csv('CAToperaciones.csv')\n",
    "datos.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "no tenemos ningun dato nulo :) de ello cuidamos en la RECOLECCIÓN DE LOS DATOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datos.isnull().values.any() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del datos['CLAVE_CLIENTE'] # para fines de modelación de momento el i del cliente no se requiere  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como nuestro objetivo es impulsar la digitalización de la Banca de inversión, excluimos de nuestra muestra a las personas morales por las siguientes:\n",
    "\n",
    "    - Los clientes de Actinver en su mayoría son personas físicas\n",
    "    - Las personas morales pueden tener más de una persona que opere sus cuentas por lo que la elección o no de los servicios digitales puede estar comprometida o condicionada por reglas propias de su negocio.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# para excluir a las personas morales, la variable 'GENERO' nos permite identificarlas\n",
    "print(datos.GENERO.value_counts())\n",
    "index = datos[ datos['GENERO'] == 'SIN GENERO'].index\n",
    "datos.drop(index, inplace=True)\n",
    "datos = datos.reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploración de los datos\n",
    "\n",
    "Veamos cómo se distribuyen nuestras variables con relación a variable a predecir, las cuales en su mayoría son categóricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# colores UP\n",
    "colores =  np.array(  ['#A4061F', '#CFAB7A', '#00529B'  ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ggplot(datos, aes(x='ENROLADO' , fill='ENROLADO')) + \\\n",
    "     geom_bar(aes(y = '(..count..)/sum(..count..)')) + \\\n",
    "     theme_minimal() + ylab('%') + scale_fill_manual(colores[0:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notamos que la variable `CVE_UNIDAD_NEGOCIO` es la misma que `UNIDAD_NEGOCIO`, por lo que eliminamos la primera"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ggplot(datos, aes(x='CVE_UNIDAD_NEGOCIO' , fill='UNIDAD_NEGOCIO')) + \\\n",
    "     geom_bar(aes(y = '(..count..)/sum(..count..)')) + \\\n",
    "     theme_minimal() + ylab('%') + scale_fill_manual(colores[1:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del datos['CVE_UNIDAD_NEGOCIO']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = datos['EMISORA_FONDO'].value_counts().index.tolist()[::-1]\n",
    "temp\n",
    "ggplot(datos) + aes(x='EMISORA_FONDO', y = '(..count..)/sum(..count..)',  fill='ENROLADO')  + geom_bar()  +\\\n",
    "  scale_x_discrete(limits=temp) + ylab('%') + theme_minimal() + \\\n",
    "     theme( legend_position='bottom', figure_size=(12, 16)) + \\\n",
    "     coord_flip() + scale_fill_manual(colores[1:3])\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = datos['DESC_CE_FINANCIERO'].value_counts().index.tolist()[::-1]\n",
    "temp\n",
    "ggplot(datos) + aes(x='DESC_CE_FINANCIERO', y = '(..count..)/sum(..count..)',  fill='ENROLADO')  + geom_bar()  +\\\n",
    "  scale_x_discrete(limits=temp) + ylab('%') + theme_minimal() + \\\n",
    "     theme( legend_position='bottom', figure_size=(16, 12)) + \\\n",
    "     coord_flip() + scale_fill_manual(colores[1:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como es común en las variables que reflejan ingresos, la variable`SALDO_CLIENTE` está sesgada positivamente por lo que trabajaremos en lo subsecuente con su logaritmo natural"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ggplot(datos, aes(x='SALDO_CLIENTE', fill='ENROLADO', color='ENROLADO')) + geom_density( alpha=0.1) + theme_minimal() +\\\n",
    "scale_fill_manual(colores[[0,2]]) + scale_color_manual(colores[[0,2]]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datos['SALDO_CLIENTE'] = np.log(datos['SALDO_CLIENTE'] + 1) # para precision numerica\n",
    "ggplot(datos, aes(x='SALDO_CLIENTE', fill='ENROLADO', color='ENROLADO')) + geom_density(alpha=0.1 ) + theme_minimal() +\\\n",
    "scale_fill_manual(colores[[0,2]]) + scale_color_manual(colores[[0,2]]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datos['TIPO_OPERACION'] =  datos['TIPO_OPERACION'].apply(lambda x : x.strip())\n",
    "temp = datos['TIPO_OPERACION'].value_counts().index.tolist()[::-1]\n",
    "ggplot(datos) + aes(x='TIPO_OPERACION', y = '(..count..)/sum(..count..)',  fill='ENROLADO')  + geom_bar()  +\\\n",
    "  scale_x_discrete(limits=temp) + ylab('%') + theme_minimal() + \\\n",
    "     theme(  figure_size=(16, 12)) + \\\n",
    "     coord_flip() + scale_fill_manual(colores[1:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ggplot(datos, aes(x='GENERO' , fill='ENROLADO')) + \\\n",
    "     geom_bar(aes(y = '(..count..)/sum(..count..)')) + \\\n",
    "     theme_minimal() + ylab('%') + scale_fill_manual(colores[0:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ggplot(datos, aes(x='Edad', fill='ENROLADO', color='ENROLADO')) + geom_density(alpha=0.1 ) + theme_minimal() +\\\n",
    "scale_fill_manual(colores[[0,2]]) + scale_color_manual(colores[[0,2]]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como el alcance del proyecto es a personas físicas omitiremos de nuestro dataset el conjunto de personas morales. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = datos[ datos['DESC_TIPO_PERS'] == 'PERSONA MORAL'].index\n",
    "datos.drop(index, inplace=True)\n",
    "#############\n",
    "index = datos[ datos['EDAD'] == 'PM'].index\n",
    "datos.drop(index, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = datos[ datos['CATEGORIA_OP'].isna() ].index # reemplazamos el nulo por un string\n",
    "datos['CATEGORIA_OP'][index] = 'NULO'\n",
    "datos['CATEGORIA_OP'] = datos['CATEGORIA_OP'].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datos = datos.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_banco = datos[ datos['UNIDAD_NEGOCIO'] == 'BANCO'].index\n",
    "index_casa_de_bolsa = datos[ datos['UNIDAD_NEGOCIO'] == 'CASA DE BOLSA'].index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Selección de características\n",
    "\n",
    "De las variables numéricas que disponemos, que corresponden con saldos en cuenta de los clientes en dos diferentes momentos, estas estan altamente correlacionadas (como lo muestra la siguiente gráfica), por lo que descartaremos la segunda como *feature* para el modelo de clasificación que construiremos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.scatter(datos['SALDO_CONTRATO'], datos['SALDO_CLIENTE'], c = datos['STATUS_BE'])\n",
    "print(np.corrcoef(datos['SALDO_CONTRATO'], datos['SALDO_CLIENTE']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del datos['SALDO_CLIENTE']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En vista de que la mayoría de las columnas con las que trabajaremos son nominales vamos a realizar un cambio de encoding. Como tenemos algunas variables con más de 25 categorías en lugar de hacer dummies estas variables usaremos un encoding que mapea a cada categoría con un entero. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_columns = datos.select_dtypes(['category']).columns\n",
    "datos[cat_columns] = datos[cat_columns].apply(lambda x: x.cat.codes)\n",
    "y = datos['STATUS_BE']\n",
    "del datos['STATUS_BE']\n",
    "print(datos.columns)\n",
    "              # copia del dataset original preprocesado\n",
    "import copy\n",
    "final = copy.deepcopy(datos) \n",
    "\n",
    "x = datos\n",
    "x.reset_index()\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(x)\n",
    "datos = scaler.transform(x)\n",
    "datos.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploración de los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dividimos el dataset en conjunto de entrenamiento y de prueba\n",
    "from sklearn.model_selection import train_test_split\n",
    "train_x, test_x, train_y, test_y = train_test_split( datos, y, test_size = 0.7, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creación de los modelos\n",
    "\n",
    "En esta sección creamos los 4 modelos correspondientes a los clasificadores: kmeans, mezcla de gaussianas, bosques aleatorios o random forest y el XGBoosting (Gradient boosting) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inicializamos los modelos que evaluaremos\n",
    "modelos = []\n",
    "from sklearn.cluster import KMeans\n",
    "modelos.append( KMeans(n_clusters = 2).fit(train_x) ) # 2 centros pues son el numero de categorias a clasificar\n",
    "\n",
    "from sklearn.mixture import GaussianMixture\n",
    "modelos.append( GaussianMixture (n_components = 2, covariance_type = 'full').fit(train_x))\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "modelos.append( RandomForestClassifier(random_state=0).fit(train_x, train_y) )\n",
    "\n",
    "import xgboost as xgb\n",
    "modelos.append( xgb.XGBClassifier(random_state=1,learning_rate=0.01).fit(train_x, train_y) )\n",
    "# tal vez sea necesario instalar la libraria y reiniciar el notebook \n",
    "# !pip install xgboost\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Primer apriori "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Segunda apriori"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluación de los modelos\n",
    "\n",
    "Entrenamos y evaluamos por medio de la precisión (*accuracy*) en el conjunto de prueba el desempeño de los modelos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "precision = []\n",
    "for i in modelos:\n",
    "    y_temp = i.predict(test_x)\n",
    "    precision.append( accuracy_score(test_y, y_temp) )\n",
    "precision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De donde obtenemos que el random forest es el segundo modelo con mayor precisión, solo marginalmente en comparación al XGB, sin embargo como RF es más interpretable lo escogemos como ganador. Procedemos a afinar el modelo por medio de sus parámetros con una búsqueda de grid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = {}\n",
    "for _ in range(0, 20):\n",
    "    model = RandomForestClassifier(n_estimators = _*4+2, random_state=0 )\n",
    "    model.fit(train_x, train_y)\n",
    "    y_temp = model.predict(test_x)    \n",
    "    grid[str(_*10+1)] =  accuracy_score(test_y, y_temp) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "scaler.fit(final)\n",
    "final = scaler.transform(final)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Donde el mejor modelo lo obtenemos con 101 árboles en el bosque."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestClassifier(n_estimators = 101, random_state=0 )\n",
    "model.fit(final, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para elegir los limites de probabilidad con los que clasificaremos, obtenemos los dos centroides de cada estrato formado por los valores ‘BANCO’ y ‘CASA DE BOLSA’ de la variable ‘UNIDAD_NEGOCIO’. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "kmeans = KMeans(n_clusters = 3, max_iter = 2000, random_state=0).fit( final[index_banco, :] )\n",
    "banco_limites  = model.predict_proba( kmeans.cluster_centers_ )[:, 1] # probabilidad de tener banca electronica \n",
    "print(banco_limites)\n",
    "kmeans = KMeans(n_clusters = 3, max_iter = 2000, random_state=0).fit( final[index_casa_de_bolsa, :] )\n",
    "casa_limites  = model.predict_proba( kmeans.cluster_centers_ )[:,1] # probabilidad de tener banca electronica \n",
    "print(casa_limites)\n",
    "\n",
    "y_prob = pd.DataFrame(model.predict_proba(final)[:,  1]  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "limite_banco = np.max(banco_limites)\n",
    "limite_casa = np.max(casa_limites)\n",
    "print(limite_banco)\n",
    "print(limite_casa)\n",
    "y_prob.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final =pd.DataFrame(final)\n",
    "final['STATUS_BE'] = y\n",
    "y_prob = y_prob.reset_index(drop = True)\n",
    "final[['Prediction']] = y_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CLASIFICACAMOS CON LOS LIMITES QUE CALCULAMOS\n",
    "mask = final['Prediction'][ index_banco ] > limite_banco\n",
    "final['Prediction'][ index_banco ] = np.where( mask == True, 1, 0 )\n",
    "mask = final['Prediction'][ index_casa_de_bolsa ] > limite_casa\n",
    "final['Prediction'][ index_casa_de_bolsa ] = np.where( mask == True, 1, 0 )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix( y, final['Prediction'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final.to_csv('Final.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(222)/(2090+222)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Así con el modelo (Random Forest) elegido y los limites de probabilidad para clasificar, calculados con base en la clasificación no supervisada de los estratos de ‘BANCO’ y ‘CASA DE BOLSA’ , podemos identificar a 222 usuarios más propensos a no requerir los servicios del call center. \n",
    "Esto representa cerca del 10% en disminución de la carga de trabajo y costos que conlleva operar el CC. \n",
    "\n",
    "Es de notar que el __modelo seleccionado no clasifica a ningún usuario que no usa el CC como posible usuario del mismo__.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Distribuciones a posteriori "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
